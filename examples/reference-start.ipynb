{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c34f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import chython\n",
    "import chytorch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from chytorch.nn import MoleculeEncoder\n",
    "from chython import smiles\n",
    "from chytorch.utils import data\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, recall_score, precision_score\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def9c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mols2containers(path_to_smi):\n",
    "    mol_containers = []\n",
    "    for r in chython.SMILESRead(path_to_smi):\n",
    "        r.canonicalize()  # fix aromaticity and functional groups\n",
    "        mol_containers.append(r)\n",
    "    return mol_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03766ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeEncoder(\n",
       "  (atoms_encoder): Embedding(121, 1024, padding_idx=0)\n",
       "  (centrality_encoder): Embedding(17, 1024, padding_idx=0)\n",
       "  (spatial_encoder): Embedding(13, 16, padding_idx=0)\n",
       "  (layer): EncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "    (linear2): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "    (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    (activation): GELU(approximate=none)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MoleculeEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1edd881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.input_enсoder = MoleculeEncoder()\n",
    "        сумма\n",
    "        self.linear1 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.linear2 = nn.Linear(in_features=512, out_features=1) #https://stats.stackexchange.com/questions/207049/neural-network-for-binary-classification-use-1-or-2-output-neurons\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        E = self.input_enсoder(X)\n",
    "        \n",
    "        X = self.linear1(E) # pass data through linear layer №1\n",
    "        X = torch.relu(X) # use the activation function over X\n",
    "        \n",
    "        X = self.dropout1(X)\n",
    "        \n",
    "        X = self.linear2(X)\n",
    "        X = torch.relu(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d13239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"\")\n",
    "df = df[['std_smiles', 'activity', 'dataset']]\n",
    "mol_containers_train = [smiles(i) for i in df[df.dataset == 'train'].std_smiles[:100]]\n",
    "y_train = df[df.dataset == 'train'].activity[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f483bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(mol_containers_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ad4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = Dataset(mol_containers_train, y_train.to_list())\n",
    "\n",
    "# class Data(Dataset):\n",
    "#     def __init__(self, X_train, y_train):\n",
    "#         self.X = X_train\n",
    "#         self.y = torch.from_numpy(y_train.to_numpy().astype(np.float32))\n",
    "# #         self.len = self.X.shape[0]\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.X[index], self.y[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ebd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 #64\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 3\n",
    "\n",
    "# mol_containers = mols2containers('../docs/input-files/mols-for-prediction.smi')\n",
    "train_set_X = data.MoleculeDataset(mol_containers_train, add_cls=True)\n",
    "dataset_loader = DataLoader(train_set_X, collate_fn=data.collate_molecules, batch_size=BATCH_SIZE)\n",
    "\n",
    "network = Network()\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = ExponentialLR(optimizer, gamma=0.9) #gamma=0.9, just from example https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f684e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_X = data.MoleculeDataset(mol_containers_train, add_cls=True)\n",
    "data_loader = torch.utils.data.DataLoader(train_set_X, collate_fn=data.collate_molecules, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc909c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (input_enсoder): MoleculeEncoder(\n",
       "    (atoms_encoder): Embedding(121, 1024, padding_idx=0)\n",
       "    (centrality_encoder): Embedding(17, 1024, padding_idx=0)\n",
       "    (spatial_encoder): Embedding(13, 16, padding_idx=0)\n",
       "    (layer): EncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "      (linear2): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "      (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (activation): GELU(approximate=none)\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9af563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(tensor([[ 1, 37,  8,  8,  9,  9,  8,  8,  9,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  8,  8,  8,  8,  8,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  8,  8,  9,  8,  8,\n",
      "          8,  8,  8,  8,  8,  8,  8,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  8,  8,  9,  8,  8,\n",
      "          8,  8,  8,  8,  8,  8,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  8,  8,  9,  8,  8,\n",
      "          8,  8,  8,  9,  8,  8,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  8,  8,  8,  8,  9,\n",
      "          9,  8,  9,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  8,  9,  8,  9,  8,\n",
      "          8, 10,  8,  8,  9,  8,  9,  8,  8, 10,  8,  8,  9],\n",
      "        [ 1, 37,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  8,  9,  8,  8,  8,\n",
      "          8,  8,  8,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8, 37, 37, 37,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8, 37,  8,  8,  8,  8, 37,  8, 37,  8,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 37,  8,  8,  8,  9,  8, 18,  8,  8,  8,  8,  8,  8,  8,  9,  8, 18,\n",
      "          8,  8,  8,  8, 10,  8,  8,  8,  8,  0,  0,  0,  0]],\n",
      "       dtype=torch.int32), tensor([[0, 3, 5, 5, 4, 5, 6, 6, 5, 6, 5, 4, 4, 4, 4, 4, 6, 6, 5, 5, 4, 4, 4, 4,\n",
      "         4, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 6, 6, 5, 6, 5, 4, 4, 4, 4, 4, 6,\n",
      "         6, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 6, 6, 5, 5, 4, 4, 4, 4, 4, 6, 6,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 6, 6, 5, 5, 4, 4, 4, 4, 4, 6, 6,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 4, 4, 5, 4, 4, 4, 5, 4, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 4, 5, 5, 6, 6, 4, 6, 6, 4, 5,\n",
      "         5, 6, 6, 4, 6, 6, 4],\n",
      "        [0, 3, 5, 5, 5, 4, 4, 4, 4, 4, 5, 4, 5, 5, 4, 5, 4, 4, 4, 4, 5, 5, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 6, 6, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 6, 6, 3, 6, 6, 6, 6, 3, 6, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 3, 6, 6, 6, 5, 5, 4, 6, 5, 4, 4, 4, 4, 4, 4, 5, 4, 5, 5, 5, 5, 4, 6,\n",
      "         6, 6, 6, 0, 0, 0, 0]], dtype=torch.int32), tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 2, 3,  ..., 0, 0, 0],\n",
      "         [1, 3, 2,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 2, 3,  ..., 0, 0, 0],\n",
      "         [1, 3, 2,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 2, 3,  ..., 0, 0, 0],\n",
      "         [1, 3, 2,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 2, 3,  ..., 0, 0, 0],\n",
      "         [1, 3, 2,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 2, 3,  ..., 0, 0, 0],\n",
      "         [1, 3, 2,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 2, 3,  ..., 0, 0, 0],\n",
      "         [1, 3, 2,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]], dtype=torch.int32))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                 | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([])) that is different to the input size (torch.Size([10, 31])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outputs), \u001b[38;5;28mlen\u001b[39m(outputs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# backprop\u001b[39;00m\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/chem-predictions-herg-0LRN4qA4-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/chem-predictions-herg-0LRN4qA4-py3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py:613\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/chem-predictions-herg-0LRN4qA4-py3.9/lib/python3.9/site-packages/torch/nn/functional.py:3074\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3074\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3076\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[1;32m   3079\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3080\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([])) that is different to the input size (torch.Size([10, 31])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "epoch_loss = []\n",
    "epoch_roc = []\n",
    "epoch_internal_roc = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    running_loss = []\n",
    "    \n",
    "    for inputs, labels in zip(dataset_loader, torch.from_numpy(y_train.to_numpy().astype(np.float32))):\n",
    "        \n",
    "         # sets the gradients to zero.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate output\n",
    "        print(len(inputs))\n",
    "        print(inputs)\n",
    "        outputs = network(inputs)\n",
    "        print(len(outputs), len(outputs[0]))\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_func(outputs.squeeze(-1), labels)\n",
    "        \n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # count statistics\n",
    "        running_loss.append(loss.item())\n",
    "        \n",
    "    # because learning rate is exponential\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    y_test_internal_pred = network(X_test_internal)\n",
    "    \n",
    "    # just for memory reducing \n",
    "    with torch.no_grad():\n",
    "        epoch_loss.append(round((sum(running_loss) / len(running_loss)), 3))\n",
    "        epoch_roc.append(roc_auc_score(y_true=train_set.y.detach().numpy(), \n",
    "                                       y_score=network(train_set.X).detach().numpy()))\n",
    "        epoch_internal_roc.append(roc_auc_score(y_true=y_test_internal, y_score=y_test_internal_pred.detach().numpy()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df7a155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "for r1 in chython.SMILESRead('/Users/khakimova/Desktop/bi-code/chem-predictions-herg/docs/input-files/mols-for-prediction.smi'):\n",
    "    r1.canonicalize()  # fix aromaticity and functional groups\n",
    "    data1.append(r1)\n",
    "\n",
    "    \n",
    "ds1 = chytorch.utils.data.MoleculeDataset(data1)\n",
    "dl1 = torch.utils.data.DataLoader(ds1, collate_fn=chytorch.utils.data.collate_molecules, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2982b78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3719, -0.8104, -0.0421,  ..., -0.3444, -1.5525, -0.6976],\n",
      "         [ 0.1037, -0.9255,  0.7589,  ..., -1.1748, -1.2558, -0.9303],\n",
      "         [ 0.3078, -1.3107,  0.6972,  ..., -0.6501, -1.5743, -0.8690],\n",
      "         ...,\n",
      "         [ 0.0336, -0.9558,  0.5205,  ..., -0.6627, -1.1989, -0.6504],\n",
      "         [ 0.0565, -1.1160,  0.7482,  ..., -1.1586, -1.0908, -0.6362],\n",
      "         [-0.0206, -1.0806,  0.6765,  ..., -0.9838, -1.2143, -1.1039]],\n",
      "\n",
      "        [[-0.5408, -0.2863,  1.0533,  ..., -1.0741, -0.6845, -0.6899],\n",
      "         [-0.5157, -0.6347,  1.0107,  ..., -1.7792, -0.6318, -0.2591],\n",
      "         [-0.0145, -0.5943,  0.5960,  ..., -1.5441,  0.0184, -0.0134],\n",
      "         ...,\n",
      "         [-0.1430, -0.5330,  0.8573,  ..., -2.3832, -0.4230, -0.2200],\n",
      "         [-0.4149, -0.6341,  2.3221,  ..., -1.7311, -1.0508,  0.0051],\n",
      "         [-0.3550,  0.1649, -0.4519,  ..., -0.8924, -0.4228, -0.8496]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "encoder = chytorch.nn.MoleculeEncoder()\n",
    "\n",
    "for i, b in enumerate(dl1):\n",
    "    print(encoder(b))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b402a2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[1, 8, 8, 8, 8, 8, 8],\n",
       "          [1, 8, 8, 8, 8, 9, 0]], dtype=torch.int32),\n",
       "  tensor([[0, 5, 5, 5, 5, 5, 5],\n",
       "          [0, 6, 6, 6, 6, 5, 0]], dtype=torch.int32),\n",
       "  tensor([[[1, 1, 1, 1, 1, 1, 1],\n",
       "           [1, 2, 3, 4, 5, 4, 3],\n",
       "           [1, 3, 2, 3, 4, 5, 4],\n",
       "           [1, 4, 3, 2, 3, 4, 5],\n",
       "           [1, 5, 4, 3, 2, 3, 4],\n",
       "           [1, 4, 5, 4, 3, 2, 3],\n",
       "           [1, 3, 4, 5, 4, 3, 2]],\n",
       "  \n",
       "          [[1, 1, 1, 1, 1, 1, 0],\n",
       "           [1, 2, 3, 4, 5, 6, 0],\n",
       "           [1, 3, 2, 3, 4, 5, 0],\n",
       "           [1, 4, 3, 2, 3, 4, 0],\n",
       "           [1, 5, 4, 3, 2, 3, 0],\n",
       "           [1, 6, 5, 4, 3, 2, 0],\n",
       "           [1, 0, 0, 0, 0, 0, 0]]], dtype=torch.int32))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dl1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367ee40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem-predictions-herg",
   "language": "python",
   "name": "chem-predictions-herg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
